{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Practice Activity 7.1: Cross-Validation and Tuning\"\n",
        "format: \n",
        "  html:\n",
        "    theme: lux\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2Kx_4ykbWKw"
      },
      "source": [
        "# 7.1\n",
        "# Part 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vpqlLnSbT_d",
        "outputId": "21ec3417-9206-4a56-bc44-4a8859692312"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 1 RMSE: 57988.68895994643\n",
            "Model 2 RMSE: 56501.64843884793\n",
            "Model 3 RMSE: 55999.430198952774\n",
            "Model 4 RMSE: 56117.68770884771\n",
            "\n",
            "Best model: Model 3 with RMSE of 55999.430198952774\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load dataset\n",
        "ames = pd.read_csv(\"/content/AmesHousing (1).csv\")\n",
        "\n",
        "# Define features and target\n",
        "X = ames[['Gr Liv Area', 'TotRms AbvGrd', 'Bldg Type']]\n",
        "y = ames['SalePrice']\n",
        "\n",
        "# Split the data once for consistent test set across models\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# 1. Model 1: Using only size and number of rooms\n",
        "ct_1 = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"standardize\", StandardScaler(), [\"Gr Liv Area\", \"TotRms AbvGrd\"])\n",
        "    ],\n",
        "    remainder=\"drop\"\n",
        ")\n",
        "model_1 = Pipeline([\n",
        "    (\"preprocessing\", ct_1),\n",
        "    (\"linear_regression\", LinearRegression())\n",
        "])\n",
        "\n",
        "# 2. Model 2: Using size, number of rooms, and building type\n",
        "ct_2 = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"dummify\", OneHotEncoder(sparse_output=False), [\"Bldg Type\"]),\n",
        "        (\"standardize\", StandardScaler(), [\"Gr Liv Area\", \"TotRms AbvGrd\"])\n",
        "    ],\n",
        "    remainder=\"drop\"\n",
        ")\n",
        "model_2 = Pipeline([\n",
        "    (\"preprocessing\", ct_2),\n",
        "    (\"linear_regression\", LinearRegression())\n",
        "])\n",
        "\n",
        "# 3. Model 3: Using size and building type, and their interaction\n",
        "ct_3 = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"dummify\", OneHotEncoder(sparse_output=False, drop='first'), [\"Bldg Type\"]),\n",
        "        (\"standardize\", StandardScaler(), [\"Gr Liv Area\"])\n",
        "    ],\n",
        "    remainder=\"drop\"\n",
        ")\n",
        "model_3 = Pipeline([\n",
        "    (\"preprocessing\", ct_3),\n",
        "    (\"interaction\", PolynomialFeatures(interaction_only=True, include_bias=False)),\n",
        "    (\"linear_regression\", LinearRegression())\n",
        "])\n",
        "\n",
        "# 4. Model 4: Using 5-degree polynomial on size, 5-degree polynomial on number of rooms, and building type\n",
        "ct_4 = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"dummify\", OneHotEncoder(sparse_output=False), [\"Bldg Type\"]),\n",
        "        (\"poly_size\", PolynomialFeatures(degree=5, include_bias=False), [\"Gr Liv Area\"]),\n",
        "        (\"poly_rooms\", PolynomialFeatures(degree=5, include_bias=False), [\"TotRms AbvGrd\"])\n",
        "    ],\n",
        "    remainder=\"drop\"\n",
        ")\n",
        "model_4 = Pipeline([\n",
        "    (\"preprocessing\", ct_4),\n",
        "    (\"linear_regression\", LinearRegression())\n",
        "])\n",
        "\n",
        "# List of models\n",
        "models = [model_1, model_2, model_3, model_4]\n",
        "model_names = [\"Model 1\", \"Model 2\", \"Model 3\", \"Model 4\"]\n",
        "rmse_scores = {}\n",
        "\n",
        "# Fit each model, make predictions, and calculate RMSE\n",
        "for i, model in enumerate(models):\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
        "    rmse_scores[model_names[i]] = rmse\n",
        "    print(f\"{model_names[i]} RMSE: {rmse}\")\n",
        "\n",
        "# Find the model with the lowest RMSE\n",
        "best_model = min(rmse_scores, key=rmse_scores.get)\n",
        "print(f\"\\nBest model: {best_model} with RMSE of {rmse_scores[best_model]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfzs89WPcD9J"
      },
      "source": [
        "# Part 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyL6T1gTcC1G",
        "outputId": "c2fde0ea-4bea-4002-bf8b-94bc66537064"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 1 Cross-validated RMSE: 55806.32634926364\n",
            "Model 2 Cross-validated RMSE: 54140.66302092876\n",
            "Model 3 Cross-validated RMSE: 53430.92197532814\n",
            "Model 4 Cross-validated RMSE: 56303.18380514651\n",
            "\n",
            "Preferred model based on cross-validated RMSE: Model 3 with RMSE of 53430.92197532814\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Define a helper function to calculate RMSE from cross_val_score\n",
        "def rmse_cross_val(model, X, y):\n",
        "    # Get negative MSE scores and convert to positive RMSE\n",
        "    neg_mse_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
        "    rmse_scores = np.sqrt(-neg_mse_scores)  # Convert negative MSE to positive RMSE\n",
        "    return rmse_scores.mean()\n",
        "\n",
        "# Calculate cross-validated RMSE for each model\n",
        "cross_val_rmse_scores = {}\n",
        "for i, model in enumerate(models):\n",
        "    rmse = rmse_cross_val(model, X, y)\n",
        "    cross_val_rmse_scores[model_names[i]] = rmse\n",
        "    print(f\"{model_names[i]} Cross-validated RMSE: {rmse}\")\n",
        "\n",
        "# Identify the model with the lowest cross-validated RMSE\n",
        "best_cv_model = min(cross_val_rmse_scores, key=cross_val_rmse_scores.get)\n",
        "print(f\"\\nPreferred model based on cross-validated RMSE: {best_cv_model} with RMSE of {cross_val_rmse_scores[best_cv_model]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQRo3tb6Pq2l"
      },
      "source": [
        "# Part 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfDIi7uWxpjn",
        "outputId": "6ac2545e-a274-4ff3-989e-5d2a7b4aaf36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Model: Pipeline(steps=[('preprocessing',\n",
            "                 ColumnTransformer(transformers=[('dummify',\n",
            "                                                  OneHotEncoder(sparse_output=False),\n",
            "                                                  ['Bldg Type']),\n",
            "                                                 ('polynomial',\n",
            "                                                  PolynomialFeatures(degree=3),\n",
            "                                                  ['Gr Liv Area',\n",
            "                                                   'TotRms AbvGrd'])])),\n",
            "                ('linear_regression', LinearRegression())])\n",
            "Best R-squared Score: 0.5410026448115971\n",
            "\n",
            "Cross-validated scores for each degree:\n",
            "    degrees      scores\n",
            "0        1    0.532882\n",
            "1        2    0.531259\n",
            "2        3    0.541003\n",
            "3        4    0.530984\n",
            "4        5    0.399898\n",
            "5        6   -1.410547\n",
            "6        7  -20.793747\n",
            "7        8 -132.190776\n",
            "8        9 -568.868517\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Load the dataset (assuming the CSV file path is \"/content/AmesHousing (1).csv\")\n",
        "ames = pd.read_csv(\"/content/AmesHousing (1).csv\")\n",
        "\n",
        "# Define features and target\n",
        "X = ames[['Gr Liv Area', 'TotRms AbvGrd', 'Bldg Type']]\n",
        "y = ames['SalePrice']\n",
        "\n",
        "# Column transformer setup\n",
        "ct_poly = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"dummify\", OneHotEncoder(sparse_output=False), [\"Bldg Type\"]),\n",
        "        (\"polynomial\", PolynomialFeatures(), [\"Gr Liv Area\", \"TotRms AbvGrd\"])\n",
        "    ],\n",
        "    remainder=\"drop\"\n",
        ")\n",
        "\n",
        "# Pipeline with PolynomialFeatures and LinearRegression\n",
        "lr_pipeline_poly = Pipeline([\n",
        "    (\"preprocessing\", ct_poly),\n",
        "    (\"linear_regression\", LinearRegression())\n",
        "]).set_output(transform=\"pandas\")\n",
        "\n",
        "# Degree range for tuning\n",
        "degrees = {'preprocessing__polynomial__degree': np.arange(1, 10)}  # Degrees 1 to 9\n",
        "\n",
        "# Grid search with cross-validation\n",
        "gscv = GridSearchCV(lr_pipeline_poly, degrees, cv=5, scoring='r2', n_jobs=-1)\n",
        "gscv_fitted = gscv.fit(X, y)\n",
        "\n",
        "# Extract cross-validated metrics\n",
        "cv_results = pd.DataFrame({\n",
        "    \"degrees\": np.arange(1, 10),\n",
        "    \"scores\": gscv_fitted.cv_results_['mean_test_score']\n",
        "})\n",
        "\n",
        "# Display the best model and corresponding cross-validated score\n",
        "best_model = gscv_fitted.best_estimator_\n",
        "best_score = gscv_fitted.best_score_\n",
        "\n",
        "print(\"Best Model:\", best_model)\n",
        "print(\"Best R-squared Score:\", best_score)\n",
        "print(\"\\nCross-validated scores for each degree:\\n\", cv_results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2H9NebKZMdel"
      },
      "source": [
        "# Question 1\n",
        "The best model found by GridSearchCV is a polynomial regression model with a degree of 3 applied to Gr Liv Area and TotRms AbvGrd. The model includes:\n",
        "\n",
        "- One-hot encoding for Bldg Type.\n",
        "- Standard scaling for Gr Liv Area and TotRms AbvGrd.\n",
        "- A polynomial transformation with a degree of 3.\n",
        "\n",
        "# Question 2\n",
        "Trying all model options can take a lot of time and processing power, especially with large datasets and high polynomial degrees, and it risks overfitting, which means the model may not work well on new data. To simplify, we could start with a smaller range of degrees (like 1 to 4) and only add complexity if needed. Another approach is using RandomizedSearchCV to sample from the range instead of testing every option, saving time while still finding good results."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

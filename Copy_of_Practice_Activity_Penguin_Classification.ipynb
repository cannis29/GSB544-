{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"8.2\"\n",
        "format: \n",
        "  html:\n",
        "    theme: lux\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxbDFsJARAMD"
      },
      "source": [
        "# Palmer Penguins Modeling\n",
        "\n",
        "Import the Palmer Penguins dataset and print out the first few rows.\n",
        "\n",
        "Suppose we want to predict `species` using the other variables in the dataset.\n",
        "\n",
        "**Dummify** all variables that require this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QV2uolyOQ65C"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, roc_curve, roc_auc_score, accuracy_score\n",
        ")\n",
        "from plotnine import ggplot, aes, geom_line, geom_abline, labs, theme_minimal\n",
        "\n",
        "# Load the Palmer Penguins dataset\n",
        "penguins = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/inst/extdata/penguins.csv\"\n",
        ")\n",
        "\n",
        "# Drop rows with missing values\n",
        "penguins = penguins.dropna()\n",
        "\n",
        "# Split the data into features and target\n",
        "X = penguins.drop(columns=[\"species\"])\n",
        "y = penguins[\"species\"]\n",
        "\n",
        "# Dummify categorical variables\n",
        "categorical_cols = X.select_dtypes(include=[\"object\"]).columns\n",
        "numerical_cols = X.select_dtypes(include=[\"float\", \"int\"]).columns\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), numerical_cols),\n",
        "        (\"cat\", OneHotEncoder(), categorical_cols),\n",
        "    ]\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HecNBVAnRHod"
      },
      "source": [
        "Let's use the other variables to predict `species`. Prepare your data and fit the following models on the entire dataset:\n",
        "\n",
        "* Two kNN models (for different values of K)\n",
        "* Two decision tree models (for different complexities of trees)\n",
        "\n",
        "Compute the following, for each of your models, on test data. Keep in mind that you may need to stratify your creation of the training and test data.\n",
        "\n",
        "* Confusion matrix\n",
        "* Overall Accuracy\n",
        "* Precision, Recall, AUC, and F1-score for each species\n",
        "\n",
        "Create one ROC plot for the species of your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1onRGJQR8T_",
        "outputId": "dd4e1744-8af5-4b1b-cc96-74800bcb9fbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<ggplot: (640 x 480)>\n",
            "Model: Decision Tree (depth=5)\n",
            "Accuracy: 0.9500\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Adelie       0.95      0.93      0.94        44\n",
            "   Chinstrap       0.87      1.00      0.93        20\n",
            "      Gentoo       1.00      0.94      0.97        36\n",
            "\n",
            "    accuracy                           0.95       100\n",
            "   macro avg       0.94      0.96      0.95       100\n",
            "weighted avg       0.95      0.95      0.95       100\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    \"kNN (k=3)\": Pipeline([\n",
        "        (\"preprocessor\", preprocessor),\n",
        "        (\"knn\", KNeighborsClassifier(n_neighbors=3))\n",
        "    ]),\n",
        "    \"kNN (k=7)\": Pipeline([\n",
        "        (\"preprocessor\", preprocessor),\n",
        "        (\"knn\", KNeighborsClassifier(n_neighbors=7))\n",
        "    ]),\n",
        "    \"Decision Tree (depth=3)\": Pipeline([\n",
        "        (\"preprocessor\", preprocessor),\n",
        "        (\"tree\", DecisionTreeClassifier(max_depth=3, random_state=42))\n",
        "    ]),\n",
        "    \"Decision Tree (depth=5)\": Pipeline([\n",
        "        (\"preprocessor\", preprocessor),\n",
        "        (\"tree\", DecisionTreeClassifier(max_depth=5, random_state=42))\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Train and evaluate models\n",
        "results = []\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_prob = model.predict_proba(X_test)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    # Collect results for Gentoo-specific ROC curve\n",
        "    if model_name == \"kNN (k=3)\":  # Example: Use kNN (k=3) for ROC\n",
        "        gentoo_binary_test = (y_test == \"Gentoo\").astype(int)\n",
        "        gentoo_pred_prob = y_pred_prob[:, np.where(model.classes_ == \"Gentoo\")[0][0]]\n",
        "        fpr, tpr, thresholds = roc_curve(gentoo_binary_test, gentoo_pred_prob)\n",
        "        roc_auc = roc_auc_score(gentoo_binary_test, gentoo_pred_prob)\n",
        "\n",
        "        # Create DataFrame for plot\n",
        "        roc_data = pd.DataFrame({\"FPR\": fpr, \"TPR\": tpr})\n",
        "\n",
        "# Plot the ROC curve using plotnine\n",
        "roc_plot = (\n",
        "    ggplot(roc_data, aes(x=\"FPR\", y=\"TPR\")) +\n",
        "    geom_line(color=\"blue\", size=1) +\n",
        "    geom_abline(intercept=0, slope=1, linetype=\"dashed\", color=\"gray\") +\n",
        "    labs(\n",
        "        title=f\"ROC Curve for Gentoo (kNN k=3, AUC = {roc_auc:.2f})\",\n",
        "        x=\"False Positive Rate (FPR)\",\n",
        "        y=\"True Positive Rate (TPR)\"\n",
        "    ) +\n",
        "    theme_minimal()\n",
        ")\n",
        "\n",
        "print(roc_plot)\n",
        "\n",
        "# Print summary of model performance\n",
        "print(f\"Model: {model_name}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
